{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53",
      "metadata": {},
      "source": [
        "# How to create a custom checkpointer using Redis\n",
        "\n",
        "When creating LangGraph agents, you can also set them up so that they persist their state. This allows you to do things like interact with an agent multiple times and have it remember previous interactions. Make sure that you have Redis running on port `6379` for going through this tutorial\n",
        "\n",
        "This example shows how to use `Redis` as the backend for persisting checkpoint state.\n",
        "\n",
        "NOTE: this is just an example implementation. You can implement your own checkpointer using a different database or modify this one as long as it conforms to the `BaseCheckpointSaver` interface."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aac2830",
      "metadata": {},
      "source": [
        "## Install the necessary libraries for Redis on Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "faadfb1b-cebe-4dcf-82fd-34044c380bc4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U redis langgraph langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6a4e417",
      "metadata": {},
      "source": [
        "## Checkpointer implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a35dba8e-5562-4803-ad80-160f53592dd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Implementation of a langgraph checkpoint saver using Redis.\"\"\"\n",
        "import logging\n",
        "from contextlib import asynccontextmanager, contextmanager\n",
        "from typing import Any, AsyncGenerator, Generator, List, Optional, Tuple, Union\n",
        "import redis\n",
        "from redis.asyncio import ConnectionPool as AsyncConnectionPool\n",
        "from redis.asyncio import Redis as AsyncRedis\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.checkpoint.base import BaseCheckpointSaver, Checkpoint, CheckpointMetadata, CheckpointTuple\n",
        "from langgraph.checkpoint.serde.jsonplus import JsonPlusSerializer\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Serializer class\n",
        "class JsonAndBinarySerializer(JsonPlusSerializer):\n",
        "    \"\"\"Serializer to handle both JSON and binary data.\"\"\"\n",
        "    def _default(self, obj: Any) -> Any:\n",
        "        if isinstance(obj, (bytes, bytearray)):\n",
        "            return self._encode_constructor_args(\n",
        "                obj.__class__, method=\"fromhex\", args=[obj.hex()]\n",
        "            )\n",
        "        return super()._default(obj)\n",
        "\n",
        "    def dumps(self, obj: Any) -> str:\n",
        "        \"\"\"Serialize object to a JSON string.\"\"\"\n",
        "        try:\n",
        "            if isinstance(obj, (bytes, bytearray)):\n",
        "                return obj.hex()\n",
        "            return super().dumps(obj)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Serialization error: {e}\")\n",
        "            raise\n",
        "\n",
        "    def loads(self, s: str, is_binary: bool = False) -> Any:\n",
        "        \"\"\"Deserialize object from a JSON string.\"\"\"\n",
        "        try:\n",
        "            if is_binary:\n",
        "                return bytes.fromhex(s)\n",
        "            return super().loads(s)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Deserialization error: {e}\")\n",
        "            raise\n",
        "\n",
        "# Connection initialization\n",
        "def initialize_sync_pool(host: str = \"localhost\", port: int = 6379, db: int = 0, **kwargs) -> redis.ConnectionPool:\n",
        "    \"\"\"Initialize a synchronous Redis connection pool.\"\"\"\n",
        "    try:\n",
        "        pool = redis.ConnectionPool(host=host, port=port, db=db, **kwargs)\n",
        "        logger.info(f\"Synchronous Redis pool initialized with host={host}, port={port}, db={db}\")\n",
        "        return pool\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error initializing sync pool: {e}\")\n",
        "        raise\n",
        "\n",
        "def initialize_async_pool(url: str = \"redis://localhost\", **kwargs) -> AsyncConnectionPool:\n",
        "    \"\"\"Initialize an asynchronous Redis connection pool.\"\"\"\n",
        "    try:\n",
        "        pool = AsyncConnectionPool.from_url(url, **kwargs)\n",
        "        logger.info(f\"Asynchronous Redis pool initialized with url={url}\")\n",
        "        return pool\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error initializing async pool: {e}\")\n",
        "        raise\n",
        "\n",
        "# Connection handling context managers\n",
        "@contextmanager\n",
        "def _get_sync_connection(connection: Union[redis.Redis, redis.ConnectionPool, None]) -> Generator[redis.Redis, None, None]:\n",
        "    \"\"\"Context manager for managing synchronous Redis connections.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        if isinstance(connection, redis.Redis):\n",
        "            yield connection\n",
        "        elif isinstance(connection, redis.ConnectionPool):\n",
        "            conn = redis.Redis(connection_pool=connection)\n",
        "            yield conn\n",
        "        else:\n",
        "            raise ValueError(\"Invalid sync connection object.\")\n",
        "    except redis.ConnectionError as e:\n",
        "        logger.error(f\"Sync connection error: {e}\")\n",
        "        raise\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "@asynccontextmanager\n",
        "async def _get_async_connection(connection: Union[AsyncRedis, AsyncConnectionPool, None]) -> AsyncGenerator[AsyncRedis, None]:\n",
        "    \"\"\"Context manager for managing asynchronous Redis connections.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        if isinstance(connection, AsyncRedis):\n",
        "            yield connection\n",
        "        elif isinstance(connection, AsyncConnectionPool):\n",
        "            conn = AsyncRedis(connection_pool=connection)\n",
        "            yield conn\n",
        "        else:\n",
        "            raise ValueError(\"Invalid async connection object.\")\n",
        "    except redis.ConnectionError as e:\n",
        "        logger.error(f\"Async connection error: {e}\")\n",
        "        raise\n",
        "    finally:\n",
        "        if conn:\n",
        "            await conn.aclose()\n",
        "\n",
        "# Redis operations\n",
        "def _save_to_redis(conn, key: str, data: dict):\n",
        "    \"\"\"Save data to Redis.\"\"\"\n",
        "    try:\n",
        "        conn.hset(key, mapping=data)\n",
        "        logger.info(f\"Data stored successfully under key: {key}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to save data to Redis: {e}\")\n",
        "        raise\n",
        "\n",
        "async def _save_to_redis_async(conn, key: str, data: dict):\n",
        "    \"\"\"Asynchronously save data to Redis.\"\"\"\n",
        "    try:\n",
        "        await conn.hset(key, mapping=data)\n",
        "        logger.info(f\"Data stored successfully under key: {key}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to save data to Redis: {e}\")\n",
        "        raise\n",
        "\n",
        "def _get_redis_data(conn, key: str) -> Optional[dict]:\n",
        "    \"\"\"Retrieve data from Redis.\"\"\"\n",
        "    try:\n",
        "        data = conn.hgetall(key)\n",
        "        if data:\n",
        "            logger.info(f\"Data retrieved successfully for key: {key}\")\n",
        "            return data\n",
        "        else:\n",
        "            logger.info(f\"No valid data found for key: {key}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to retrieve data from Redis: {e}\")\n",
        "        raise\n",
        "\n",
        "async def _get_redis_data_async(conn, key: str) -> Optional[dict]:\n",
        "    \"\"\"Asynchronously retrieve data from Redis.\"\"\"\n",
        "    try:\n",
        "        data = await conn.hgetall(key)\n",
        "        if data:\n",
        "            logger.info(f\"Data retrieved successfully for key: {key}\")\n",
        "            return data\n",
        "        else:\n",
        "            logger.info(f\"No valid data found for key: {key}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to retrieve data from Redis: {e}\")\n",
        "        raise\n",
        "\n",
        "# Main class\n",
        "class RedisSaver(BaseCheckpointSaver):\n",
        "    \"\"\"Redis-based checkpoint saver implementation.\"\"\"\n",
        "    sync_connection: Optional[Union[redis.Redis, redis.ConnectionPool]] = None\n",
        "    async_connection: Optional[Union[AsyncRedis, AsyncConnectionPool]] = None\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sync_connection: Optional[Union[redis.Redis, redis.ConnectionPool]] = None,\n",
        "        async_connection: Optional[Union[AsyncRedis, AsyncConnectionPool]] = None,\n",
        "    ):\n",
        "        super().__init__(serde=JsonAndBinarySerializer())\n",
        "        self.sync_connection = sync_connection\n",
        "        self.async_connection = async_connection\n",
        "\n",
        "    def put(\n",
        "        self,\n",
        "        config: RunnableConfig,\n",
        "        checkpoint: Checkpoint,\n",
        "        metadata: CheckpointMetadata,\n",
        "    ) -> RunnableConfig:\n",
        "        \"\"\"Synchronously store a checkpoint in Redis.\"\"\"\n",
        "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
        "        key = f\"checkpoint:{thread_id}:{checkpoint['ts']}\"\n",
        "        data = {\n",
        "            \"checkpoint\": self.serde.dumps(checkpoint),\n",
        "            \"metadata\": self.serde.dumps(metadata),\n",
        "            \"parent_ts\": parent_ts if parent_ts else \"\",\n",
        "        }\n",
        "        with _get_sync_connection(self.sync_connection) as conn:\n",
        "            _save_to_redis(conn, key, data)\n",
        "        return {\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": checkpoint[\"ts\"]}}\n",
        "\n",
        "    async def aput(\n",
        "        self,\n",
        "        config: RunnableConfig,\n",
        "        checkpoint: Checkpoint,\n",
        "        metadata: CheckpointMetadata,\n",
        "    ) -> RunnableConfig:\n",
        "        \"\"\"Asynchronously store a checkpoint in Redis.\"\"\"\n",
        "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
        "        key = f\"checkpoint:{thread_id}:{checkpoint['ts']}\"\n",
        "        data = {\n",
        "            \"checkpoint\": self.serde.dumps(checkpoint),\n",
        "            \"metadata\": self.serde.dumps(metadata),\n",
        "            \"parent_ts\": parent_ts if parent_ts else \"\",\n",
        "        }\n",
        "        async with _get_async_connection(self.async_connection) as conn:\n",
        "            await _save_to_redis_async(conn, key, data)\n",
        "        return {\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": checkpoint[\"ts\"]}}\n",
        "\n",
        "    def put_writes(\n",
        "        self,\n",
        "        config: RunnableConfig,\n",
        "        writes: List[Tuple[str, Any]],\n",
        "        task_id: str,\n",
        "    ) -> RunnableConfig:\n",
        "        \"\"\"Synchronously save a list of writes to Redis storage.\"\"\"\n",
        "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "        thread_ts = config[\"configurable\"].get(\"thread_ts\") or self._default_ts()\n",
        "        key = f\"writes:{thread_id}:{thread_ts}\"\n",
        "        serialized_writes = [(channel, self.serde.dumps(value)) for channel, value in writes]\n",
        "        with _get_sync_connection(self.sync_connection) as conn:\n",
        "            for channel, value in serialized_writes:\n",
        "                conn.rpush(key, f\"{task_id}:{channel}:{value}\")\n",
        "        logger.info(f\"Writes stored successfully for thread_id: {thread_id}, ts: {thread_ts}\")\n",
        "        return config\n",
        "\n",
        "    async def aput_writes(\n",
        "        self,\n",
        "        config: RunnableConfig,\n",
        "        writes: List[Tuple[str, Any]],\n",
        "        task_id: str,\n",
        "    ) -> RunnableConfig:\n",
        "        \"\"\"Asynchronously save a list of writes to Redis storage.\"\"\"\n",
        "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "        thread_ts = config[\"configurable\"].get(\"thread_ts\") or self._default_ts()\n",
        "        key = f\"writes:{thread_id}:{thread_ts}\"\n",
        "        serialized_writes = [(channel, self.serde.dumps(value)) for channel, value in writes]\n",
        "        async with _get_async_connection(self.async_connection) as conn:\n",
        "            for channel, value in serialized_writes:\n",
        "                await conn.rpush(key, f\"{task_id}:{channel}:{value}\")\n",
        "        logger.info(f\"Writes stored successfully for thread_id: {thread_id}, ts: {thread_ts}\")\n",
        "        return config\n",
        "\n",
        "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
        "        \"\"\"Retrieve a checkpoint tuple from Redis.\"\"\"\n",
        "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "        thread_ts = config[\"configurable\"].get(\"thread_ts\")\n",
        "        with _get_sync_connection(self.sync_connection) as conn:\n",
        "            key = self._get_checkpoint_key(conn, thread_id, thread_ts)\n",
        "            if not key:\n",
        "                return None\n",
        "            checkpoint_data = _get_redis_data(conn, key)\n",
        "            return self._parse_checkpoint_data(checkpoint_data, config, thread_id)\n",
        "\n",
        "    async def aget_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
        "        \"\"\"Asynchronously retrieve a checkpoint tuple from Redis.\"\"\"\n",
        "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "        thread_ts = config[\"configurable\"].get(\"thread_ts\")\n",
        "        async with _get_async_connection(self.async_connection) as conn:\n",
        "            key = await self._aget_checkpoint_key(conn, thread_id, thread_ts)\n",
        "            if not key:\n",
        "                return None\n",
        "            checkpoint_data = await _get_redis_data_async(conn, key)\n",
        "            return self._parse_checkpoint_data(checkpoint_data, config, thread_id)\n",
        "\n",
        "    def list(\n",
        "        self,\n",
        "        config: Optional[RunnableConfig],\n",
        "        *,\n",
        "        filter: Optional[dict[str, Any]] = None,\n",
        "        before: Optional[RunnableConfig] = None,\n",
        "        limit: Optional[int] = None,\n",
        "    ) -> Generator[CheckpointTuple, None, None]:\n",
        "        \"\"\"List checkpoints from Redis.\"\"\"\n",
        "        thread_id = config[\"configurable\"][\"thread_id\"] if config else \"*\"\n",
        "        pattern = f\"checkpoint:{thread_id}:*\"\n",
        "        with _get_sync_connection(self.sync_connection) as conn:\n",
        "            keys = self._filter_keys(conn, pattern, before, limit)\n",
        "            for key in keys:\n",
        "                data = _get_redis_data(conn, key)\n",
        "                if data and b\"checkpoint\" in data and b\"metadata\" in data:\n",
        "                    yield self._parse_checkpoint_data(data, config, thread_id)\n",
        "\n",
        "    async def alist(\n",
        "        self,\n",
        "        config: Optional[RunnableConfig],\n",
        "        *,\n",
        "        filter: Optional[dict[str, Any]] = None,\n",
        "        before: Optional[RunnableConfig] = None,\n",
        "        limit: Optional[int] = None,\n",
        "    ) -> AsyncGenerator[CheckpointTuple, None]:\n",
        "        \"\"\"Asynchronously list checkpoints from Redis.\"\"\"\n",
        "        thread_id = config[\"configurable\"][\"thread_id\"] if config else \"*\"\n",
        "        pattern = f\"checkpoint:{thread_id}:*\"\n",
        "        async with _get_async_connection(self.async_connection) as conn:\n",
        "            keys = await self._afilter_keys(conn, pattern, before, limit)\n",
        "            for key in keys:\n",
        "                data = await _get_redis_data_async(conn, key)\n",
        "                if data and b\"checkpoint\" in data and b\"metadata\" in data:\n",
        "                    yield self._parse_checkpoint_data(data, config, thread_id)\n",
        "\n",
        "    # Utility methods\n",
        "    def _default_ts(self) -> str:\n",
        "        \"\"\"Generate a default timezone-aware timestamp.\"\"\"\n",
        "        return datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    def _get_checkpoint_key(self, conn, thread_id: str, thread_ts: Optional[str]) -> Optional[str]:\n",
        "        \"\"\"Determine the Redis key for a checkpoint.\"\"\"\n",
        "        if thread_ts:\n",
        "            return f\"checkpoint:{thread_id}:{thread_ts}\"\n",
        "        all_keys = conn.keys(f\"checkpoint:{thread_id}:*\")\n",
        "        if not all_keys:\n",
        "            logger.info(f\"No checkpoints found for thread_id: {thread_id}\")\n",
        "            return None\n",
        "        latest_key = max(all_keys, key=lambda k: \":\".join(k.decode().split(\":\")[2:]))\n",
        "        return latest_key.decode()\n",
        "\n",
        "    async def _aget_checkpoint_key(self, conn, thread_id: str, thread_ts: Optional[str]) -> Optional[str]:\n",
        "        \"\"\"Asynchronously determine the Redis key for a checkpoint.\"\"\"\n",
        "        if thread_ts:\n",
        "            return f\"checkpoint:{thread_id}:{thread_ts}\"\n",
        "        all_keys = await conn.keys(f\"checkpoint:{thread_id}:*\")\n",
        "        if not all_keys:\n",
        "            logger.info(f\"No checkpoints found for thread_id: {thread_id}\")\n",
        "            return None\n",
        "        latest_key = max(all_keys, key=lambda k: \":\".join(k.decode().split(\":\")[2:]))\n",
        "        return latest_key.decode()\n",
        "\n",
        "    def _filter_keys(self, conn, pattern: str, before: Optional[RunnableConfig], limit: Optional[int]) -> list:\n",
        "        \"\"\"Filter and sort Redis keys based on optional criteria.\"\"\"\n",
        "        keys = conn.keys(pattern)\n",
        "        if before:\n",
        "            keys = [\n",
        "                k\n",
        "                for k in keys\n",
        "                if \":\".join(k.decode().split(\":\")[2:])\n",
        "                < before[\"configurable\"][\"thread_ts\"]\n",
        "            ]\n",
        "        keys = sorted(keys, key=lambda k: \":\".join(k.decode().split(\":\")[2:]), reverse=True)\n",
        "        if limit:\n",
        "            keys = keys[:limit]\n",
        "        return keys\n",
        "\n",
        "    async def _afilter_keys(self, conn, pattern: str, before: Optional[RunnableConfig], limit: Optional[int]) -> list:\n",
        "        \"\"\"Asynchronously filter and sort Redis keys based on optional criteria.\"\"\"\n",
        "        keys = await conn.keys(pattern)\n",
        "        if before:\n",
        "            keys = [\n",
        "                k\n",
        "                for k in keys\n",
        "                if \":\".join(k.decode().split(\":\")[2:])\n",
        "                < before[\"configurable\"][\"thread_ts\"]\n",
        "            ]\n",
        "        keys = sorted(keys, key=lambda k: \":\".join(k.decode().split(\":\")[2:]), reverse=True)\n",
        "        if limit:\n",
        "            keys = keys[:limit]\n",
        "        return keys\n",
        "\n",
        "    def _parse_checkpoint_data(self, data: dict, config: RunnableConfig, thread_id: str) -> Optional[CheckpointTuple]:\n",
        "        \"\"\"Parse checkpoint data retrieved from Redis.\"\"\"\n",
        "        if not data:\n",
        "            logger.info(f\"No valid checkpoint data found.\")\n",
        "            return None\n",
        "        checkpoint = self.serde.loads(data[b\"checkpoint\"].decode())\n",
        "        metadata = self.serde.loads(data[b\"metadata\"].decode())\n",
        "        parent_ts = data.get(b\"parent_ts\", b\"\").decode()\n",
        "        parent_config = (\n",
        "            {\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": parent_ts}}\n",
        "            if parent_ts\n",
        "            else None\n",
        "        )\n",
        "        logger.info(f\"Checkpoint parsed successfully for thread_id: {thread_id}\")\n",
        "        return CheckpointTuple(\n",
        "            config=config,\n",
        "            checkpoint=checkpoint,\n",
        "            metadata=metadata,\n",
        "            parent_config=parent_config,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d142495",
      "metadata": {},
      "source": [
        "## Checkpointer implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456fa19c-93a5-4750-a410-f2d810b964ad",
      "metadata": {},
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eca9aafb-a155-407a-8036-682a2f1297d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e26b3204-cca2-414c-800e-7e09032445ae",
      "metadata": {},
      "source": [
        "## Setup model and tools for the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e5213193-5a7d-43e7-aeba-fe732bb1cd7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
        "    \"\"\"Use this to get weather information.\"\"\"\n",
        "    if city == \"nyc\":\n",
        "        return \"It might be cloudy in nyc\"\n",
        "    elif city == \"sf\":\n",
        "        return \"It's always sunny in sf\"\n",
        "    else:\n",
        "        raise AssertionError(\"Unknown city\")\n",
        "\n",
        "\n",
        "tools = [get_weather]\n",
        "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9342c62-dbb4-40f6-9271-7393f1ca48c4",
      "metadata": {},
      "source": [
        "## Use sync connection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e39fc712-9e1c-4831-9077-dd07b0c13594",
      "metadata": {},
      "source": [
        "### With a connection pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a1710e2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Synchronous Redis pool initialized with host=localhost, port=6379, db=0\n"
          ]
        }
      ],
      "source": [
        "sync_pool = initialize_sync_pool(host=\"localhost\", port=6379, db=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2657c1c4-d8a5-4fe3-8f77-95415a98ed6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpointer = RedisSaver(sync_connection=sync_pool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6d388241-de57-4b4e-af7b-eb1081fb8f36",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:No checkpoints found for thread_id: 1\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:1:2024-08-05T11:15:21.936463+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 1, ts: 2024-08-05T11:15:21.947055+00:00\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:1:2024-08-05T11:15:21.946487+00:00\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:1:2024-08-05T11:15:23.220949+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 1, ts: 2024-08-05T11:15:23.221984+00:00\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:1:2024-08-05T11:15:23.234523+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 1, ts: 2024-08-05T11:15:23.234523+00:00\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:1:2024-08-05T11:15:24.252761+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 1, ts: 2024-08-05T11:15:24.252761+00:00\n"
          ]
        }
      ],
      "source": [
        "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a7e0e7ec-a675-470b-9270-e4bdc59d4a4d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content=\"what's the weather in sf\", id='eea661b1-4602-4140-8a71-97909de26aee'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jLfonr3BH0UvfUKc5g0huuSL', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3cd8b62c3b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2f538aa9-ff37-4f0f-b4a0-fc33a6bfc87f-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_jLfonr3BH0UvfUKc5g0huuSL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),\n",
              "  ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='055823b2-3be9-435c-a05a-475fff942c2e', tool_call_id='call_jLfonr3BH0UvfUKc5g0huuSL'),\n",
              "  AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c832e4513b', 'finish_reason': 'stop', 'logprobs': None}, id='run-72a59db8-e09b-40bc-b884-a510a8919b68-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "96efd8b2-97c9-4207-83b2-00131723a75a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Data retrieved successfully for key: checkpoint:1:2024-08-05T11:15:24.252761+00:00\n",
            "INFO:__main__:Checkpoint parsed successfully for thread_id: 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'v': 1,\n",
              " 'ts': '2024-08-05T11:15:24.252761+00:00',\n",
              " 'id': '1ef531c0-2c67-6f82-8003-27e9d58275f2',\n",
              " 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='eea661b1-4602-4140-8a71-97909de26aee'),\n",
              "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jLfonr3BH0UvfUKc5g0huuSL', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3cd8b62c3b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2f538aa9-ff37-4f0f-b4a0-fc33a6bfc87f-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_jLfonr3BH0UvfUKc5g0huuSL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),\n",
              "   ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='055823b2-3be9-435c-a05a-475fff942c2e', tool_call_id='call_jLfonr3BH0UvfUKc5g0huuSL'),\n",
              "   AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c832e4513b', 'finish_reason': 'stop', 'logprobs': None}, id='run-72a59db8-e09b-40bc-b884-a510a8919b68-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})],\n",
              "  'agent': 'agent'},\n",
              " 'channel_versions': {'__start__': 2,\n",
              "  'messages': 5,\n",
              "  'start:agent': 3,\n",
              "  'agent': 5,\n",
              "  'branch:agent:should_continue:tools': 4,\n",
              "  'tools': 5},\n",
              " 'versions_seen': {'__input__': {},\n",
              "  '__start__': {'__start__': 1},\n",
              "  'agent': {'start:agent': 2, 'tools': 4},\n",
              "  'tools': {'branch:agent:should_continue:tools': 3}},\n",
              " 'pending_sends': [],\n",
              " 'current_tasks': {}}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpointer.get(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967c95c7-e392-4819-bd71-f29e91c68df3",
      "metadata": {},
      "source": [
        "### With a connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b7d3687b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:No checkpoints found for thread_id: 2\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:2:2024-08-05T11:15:26.024055+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 2, ts: 2024-08-05T11:15:26.029054+00:00\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:2:2024-08-05T11:15:26.029054+00:00\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:2:2024-08-05T11:15:27.036467+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 2, ts: 2024-08-05T11:15:27.037450+00:00\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:2:2024-08-05T11:15:27.043986+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 2, ts: 2024-08-05T11:15:27.043986+00:00\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:2:2024-08-05T11:15:27.837961+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 2, ts: 2024-08-05T11:15:27.837961+00:00\n",
            "INFO:__main__:Data retrieved successfully for key: checkpoint:2:2024-08-05T11:15:27.837961+00:00\n",
            "INFO:__main__:Checkpoint parsed successfully for thread_id: 2\n"
          ]
        }
      ],
      "source": [
        "import redis\n",
        "\n",
        "# Initialize the Redis synchronous direct connection\n",
        "sync_redis_direct = redis.Redis(host=\"localhost\", port=6379, db=0)\n",
        "\n",
        "# Initialize the RedisSaver with the synchronous direct connection\n",
        "checkpointer = RedisSaver(sync_connection=sync_redis_direct)\n",
        "\n",
        "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
        "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)\n",
        "\n",
        "checkpoint_tuple = checkpointer.get_tuple(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a47d3e-e588-48fc-a5d4-2145dff17e77",
      "metadata": {},
      "source": [
        "## Use async connection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee6b6cf7-d8f7-4777-a48d-93b5855fe681",
      "metadata": {},
      "source": [
        "### With a connection pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "20cea8b7-8f13-4dc7-a3c9-825040eb4c57",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Asynchronous Redis pool initialized with url=redis://localhost:6379/0\n"
          ]
        }
      ],
      "source": [
        "# Initialize a synchronous Redis connection pool\n",
        "async_pool = initialize_async_pool(url=\"redis://localhost:6379/0\")\n",
        "\n",
        "checkpointer = RedisSaver(async_connection=async_pool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f889dce6-7ec1-4277-b8af-ace7811733fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:No checkpoints found for thread_id: 3\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:3:2024-08-05T11:15:28.021390+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 3, ts: 2024-08-05T11:15:28.026390+00:00\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:3:2024-08-05T11:15:28.026390+00:00\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:3:2024-08-05T11:15:29.061047+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 3, ts: 2024-08-05T11:15:29.061047+00:00\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:3:2024-08-05T11:15:29.068415+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 3, ts: 2024-08-05T11:15:29.069415+00:00\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:3:2024-08-05T11:15:29.771410+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 3, ts: 2024-08-05T11:15:29.771410+00:00\n"
          ]
        }
      ],
      "source": [
        "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
        "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
        "res = await graph.ainvoke(\n",
        "    {\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ed58c722-1662-4ae2-9bb7-4872158a5b29",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Data retrieved successfully for key: checkpoint:3:2024-08-05T11:15:29.771410+00:00\n",
            "INFO:__main__:Checkpoint parsed successfully for thread_id: 3\n"
          ]
        }
      ],
      "source": [
        "checkpoint_tuple = await checkpointer.aget_tuple(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e0c42044-4de6-4742-8e00-fe295d50c95a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CheckpointTuple(config={'configurable': {'thread_id': '3'}}, checkpoint={'v': 1, 'ts': '2024-08-05T11:15:29.771410+00:00', 'id': '1ef531c0-6109-63b7-8003-2279817b32cc', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='31036c8a-ce5e-414a-8710-b7d52e86b5f5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_RTPP7yBwAJZymyPXnaOWYfxH', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1d9dde0b-5de9-4f0c-8a94-11db0d38e25b-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_RTPP7yBwAJZymyPXnaOWYfxH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='28898a3d-c198-4be3-8eac-ff2d4904b921', tool_call_id='call_RTPP7yBwAJZymyPXnaOWYfxH'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'stop', 'logprobs': None}, id='run-71f778e0-b238-4d00-af9b-7e3b25d944ae-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': [], 'current_tasks': {}}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'stop', 'logprobs': None}, id='run-71f778e0-b238-4d00-af9b-7e3b25d944ae-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})]}}, 'step': 3}, parent_config=None, pending_writes=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint_tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56552584-9eb8-40df-a6a0-44151018b509",
      "metadata": {},
      "source": [
        "### Use connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a7bf32bd",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:No checkpoints found for thread_id: 4\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:4:2024-08-05T11:15:30.030381+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 4, ts: 2024-08-05T11:15:30.036471+00:00\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:4:2024-08-05T11:15:30.035379+00:00\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:4:2024-08-05T11:15:30.854234+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 4, ts: 2024-08-05T11:15:30.855234+00:00\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:4:2024-08-05T11:15:30.865223+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 4, ts: 2024-08-05T11:15:30.865732+00:00\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:Data stored successfully under key: checkpoint:4:2024-08-05T11:15:31.568987+00:00\n",
            "INFO:__main__:Writes stored successfully for thread_id: 4, ts: 2024-08-05T11:15:31.569052+00:00\n",
            "INFO:__main__:Data retrieved successfully for key: b'checkpoint:4:2024-08-05T11:15:31.568987+00:00'\n",
            "INFO:__main__:Checkpoint parsed successfully for thread_id: 4\n",
            "INFO:__main__:Data retrieved successfully for key: b'checkpoint:4:2024-08-05T11:15:30.865223+00:00'\n",
            "INFO:__main__:Checkpoint parsed successfully for thread_id: 4\n",
            "INFO:__main__:Data retrieved successfully for key: b'checkpoint:4:2024-08-05T11:15:30.854234+00:00'\n",
            "INFO:__main__:Checkpoint parsed successfully for thread_id: 4\n",
            "INFO:__main__:Data retrieved successfully for key: b'checkpoint:4:2024-08-05T11:15:30.035379+00:00'\n",
            "INFO:__main__:Checkpoint parsed successfully for thread_id: 4\n",
            "INFO:__main__:Data retrieved successfully for key: b'checkpoint:4:2024-08-05T11:15:30.030381+00:00'\n",
            "INFO:__main__:Checkpoint parsed successfully for thread_id: 4\n"
          ]
        }
      ],
      "source": [
        "from redis.asyncio import Redis as AsyncRedis\n",
        "\n",
        "async with await AsyncRedis(host=\"localhost\", port=6379, db=0) as conn:\n",
        "    checkpointer = RedisSaver(async_connection=conn)\n",
        "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
        "    config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
        "    res = await graph.ainvoke(\n",
        "        {\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config\n",
        "    )\n",
        "    checkpoint_tuples = [c async for c in checkpointer.alist(config)]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
